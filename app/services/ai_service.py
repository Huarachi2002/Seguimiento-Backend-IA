"""
AI Service Module
=================

Este servicio encapsula toda la l√≥gica relacionada con la inteligencia artificial.

Responsabilidades:
1. Generar respuestas usando el modelo de lenguaje
2. Detectar intenciones en los mensajes del usuario
3. Mantener el contexto de la conversaci√≥n
4. Aplicar el prompt del sistema

Patr√≥n Service:
Separa la l√≥gica de negocio compleja de los controllers (endpoints).
Hace el c√≥digo m√°s testeable y reutilizable.
"""

from email.mime import message
import re
import json
from typing import List, Optional, Tuple
from urllib import response
from app.domain.models import Message, MessageRole, ActionIntent, Conversation
from app.domain.exceptions import ModelNotLoadedException, InvalidContextException
from app.core.config import settings
from app.core.logging import get_logger

logger = get_logger(__name__)


class AIService:
    """
    Servicio para interactuar con el modelo de IA.
    
    Este servicio act√∫a como una capa de abstracci√≥n sobre el modelo.
    Si en el futuro cambias de modelo (ej: OpenAI GPT), solo modificas
    este servicio, no todo el c√≥digo.
    """
    
    def __init__(self, model, tokenizer, device, patient_service=None):
        """
        Inicializa el servicio de IA.
        
        Args:
            model: Modelo de lenguaje cargado
            tokenizer: Tokenizer del modelo
            device: Dispositivo (cpu/cuda)
            patient_service: Servicio para consultar informaci√≥n de pacientes
        """
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.patient_service = patient_service
        self._system_context = settings.get_system_context()
        
        logger.info(f"‚úÖ AIService inicializado en dispositivo: {device}")
    
    def is_ready(self) -> bool:
        """
        Verifica si el servicio est√° listo para procesar.
        
        Returns:
            True si el modelo est√° cargado
        """
        return self.model is not None and self.tokenizer is not None
    
    async def generate_response(
        self,
        conversation: Conversation,
        user_id: str,
        max_tokens: int = None,
        temperature: float = None
    ) -> str:
        """
        Genera una respuesta basada en la conversaci√≥n.
        
        Este es el m√©todo principal del servicio. Toma una conversaci√≥n
        completa y genera la siguiente respuesta del asistente.
        
        AHORA consulta la BD para verificar si el paciente est√° registrado.
        
        Args:
            conversation: Objeto Conversation con el historial
            user_id: ID del usuario (tel√©fono) para consultar BD
            max_tokens: M√°ximo de tokens a generar (usa config si es None)
            temperature: Temperatura del modelo (usa config si es None)
        
        Returns:
            Respuesta generada como string
        
        Raises:
            ModelNotLoadedException: Si el modelo no est√° cargado
        """
        if not self.is_ready():
            raise ModelNotLoadedException()
        
        # Usar valores por defecto de configuraci√≥n si no se especifican
        max_tokens = max_tokens or settings.max_tokens
        temperature = temperature or settings.temperature
        
        logger.info(f"ü§ñ Generando respuesta para conversaci√≥n {conversation.conversation_id}")
        
        try:
            # 1. Validar Contexto antes de construir el prompt
            last_message = conversation.messages[-1].content if conversation.messages else ""

            if not self._is_valid_tuberculosis_context(last_message):
                logger.warning(f"‚ö†Ô∏è Mensaje fuera de contexto detectado: {last_message}")
                return self._get_out_of_context_response()

            # 2. Construir el prompt con contexto del sistema + historial + BD
            prompt = await self._build_prompt(conversation, user_id)
            
            # 3. Validar que el contexto es apropiado
            if not self._is_valid_context(conversation.messages[-1].content):
                return self._get_out_of_context_response()

            # 4. Generar respuesta con el modelo
            response = self._generate_with_model(
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )

            if not self._is_valid_response(response):
                logger.warning(f"‚ö†Ô∏è Respuesta inv√°lida detectada, usando respuesta por defecto")
                return self._get_fallback_response(last_message)
            
            logger.info(f"‚úÖ Respuesta generada exitosamente")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta: {e}")
            return "Lo siento, tuve un problema procesando tu mensaje. ¬øPodr√≠as reformularlo?"
    
    def _is_valid_tuberculosis_context(self, message: str) -> bool:
        """
        Valida que el mensaje sea sobre TUBERCULOSIS.
        
        Returns:
            True si es valido, False si esta fuera de contexto
        """

        message_lower = message.lower()

        # Saludos siempre son validos
        greetings = ['hola', 'buenos dias', 'buenas tardes', 'buenas noches', 'saludos', 'hi', 'hello']
        if any(greeting in message_lower for greeting in greetings):
            return True
        
        tb_keywords = [
            'tuberculosis', 'tb', 'tos', 'fiebre', 'sudor', 'peso', 'respirar',
            'cita', 'control', 'tratamiento', 'medicamento', 'pastilla',
            'agendar', 'cancelar', 'reprogramar', 'cuando', 'cu√°ndo',
            'salud', 's√≠ntoma', 'dolor', 'pecho', 'sangre'
        ]

        if any(keyword in message_lower for keyword in tb_keywords):
            return True

        if len(message.strip()) < 20 and "?" in message:
            return True
        
        out_of_context_keywords = [
            'hipotenusa', 'matem√°tica', 'trigonometr√≠a', 'f√≠sica', 'qu√≠mica',
            'odontolog√≠a', 'dentista', 'muela', 'diente',
            'embarazo', 'ginecolog√≠a', 'pediatr√≠a', 'ni√±o',
            'f√∫tbol', 'deporte', 'pol√≠tica', 'clima'
        ]

        if any(keyword in message_lower for keyword in out_of_context_keywords):
            logger.info("üéØ Mensaje identificado como fuera de contexto por palabras clave")
            return False
        
        # ‚ö†Ô∏è Mensajes largos sin palabras clave (probablemente fuera de contexto)
        if len(message.strip()) > 100:
            return False
        
        return True
    
    def _is_valid_response(self, response: str) -> bool:
        """
        Valida que la respuesta generada sea coherente

        Detecta:
        - Fechas inventadas (ej: "140032/10/2025")
        - Nombres incorrectos repetidos (ej: Diego Diego Diego)
        - Numeros absurdos (ej: "1491/20759/2010")
        - Palabras inventadas (ej: "TUBERACION")

        Returns:
            True si la respuesta es valida
        """

        # Detectar fechas absurdas (dias > 31, meses > 12)
        import re
        date_pattern = r'\d{2,}/\d{2,}/\d{2,}'
        dates = re.findall(date_pattern, response)

        for date_str in dates:
            parts = date_str.split('/')
            try:
                day = int(parts[0])
                month = int(parts[1]) if len(parts) > 1 else 0
                year = int(parts[2])
                if day > 31 or month > 12 or year > 2100 or day > 1000:
                    logger.warning(f"‚ö†Ô∏è Fecha absurda detectada: {date_str}")
                    return False
            except:
                logger.warning(f"‚ö†Ô∏è Fecha inv√°lida detectada: {date_str}")
                pass

        # Detectar palabras repetidas 3 veces seguidas
        words = response.split()
        for i in range(len(words) - 2):
            if words[i] == words[i+1] == words[i+2]:
                logger.warning(f"‚ö†Ô∏è Palabra repetida detectada: {words[i]}")
                return False
            
        # Detectar palabras inventadas conocidas
        invalid_words = ['tuberaci√≥n', 'tuberculos', 'ca√±adi', 'carmi']
        if any(word in response.lower() for word in invalid_words):
            logger.warning(f"‚ö†Ô∏è Palabra inventada detectada")
            return False      

        # Respuesta demasiado larga (indica generacion descontrolada)
        if len(response) > 400:
            logger.warning(f"‚ö†Ô∏è Respuesta demasiado larga detectada")
            return False

        return True

    def detect_action(self, message: str, conversation: Conversation) -> Optional[ActionIntent]:
        """
        Detecta si el mensaje del usuario tiene una intenci√≥n de acci√≥n.
        
        Ejemplos de acciones:
        - "Quiero agendar una cita" -> action: schedule_appointment
        - "Cancelar mi cita" -> action: cancel_appointment
        - "¬øCu√°ndo es mi pr√≥xima cita?" -> action: lookup_appointments
        
        Args:
            message: Mensaje del usuario
            conversation: Conversaci√≥n completa para contexto
        
        Returns:
            ActionIntent si se detecta una acci√≥n, None si no
        """
        message_lower = message.lower()
        
        # Detecci√≥n de intenci√≥n de agendar
        agendar_keywords = ['agendar', 'programar', 'cita nueva', 'reservar', 'quiero cita']
        if any(word in message_lower for word in agendar_keywords):
            logger.info("üéØ Acci√≥n detectada: schedule_appointment")

            # Extraer datos del mensaje
            extracted_data = self._extract_appointment_data(message)
            logger.info(f"üìä Datos extra√≠dos para agendar: {extracted_data}")
            # Determinar que datos faltan
            missing_fields = []
            if not extracted_data.get("fecha"):
                missing_fields.append("fecha")
            if not extracted_data.get("hora"):
                missing_fields.append("hora")

            return ActionIntent(
                action="schedule_appointment",
                params={
                    "status": "collecting_info" if missing_fields else "ready",
                    "extracted_data": extracted_data,
                    "missing_fields": missing_fields 
                    },
                confidence=0.9
            )
        
        # Detecci√≥n de intenci√≥n de cancelar
        if any(word in message_lower for word in ['cancelar', 'anular']):
            logger.info("üéØ Acci√≥n detectada: cancel_appointment")
            return ActionIntent(
                action="cancel_appointment",
                params={"status": "collecting_info"},
                confidence=0.85
            )
        
        # Detecci√≥n de intenci√≥n de reprogramar
        if any(word in message_lower for word in ['reprogramar', 'cambiar', 'mover cita']):
            logger.info("üéØ Acci√≥n detectada: reschedule_appointment")
            return ActionIntent(
                action="reschedule_appointment",
                params={"status": "collecting_info"},
                confidence=0.85
            )
        
        # Detecci√≥n de consulta de citas
        if any(word in message_lower for word in ['pr√≥xima cita', 'mis citas', 'cu√°ndo', 'cuando']):
            logger.info("üéØ Acci√≥n detectada: lookup_appointments")
            return ActionIntent(
                action="lookup_appointments",
                params={},
                confidence=0.8
            )
        
        # Detecci√≥n de verificaci√≥n de identidad
        if re.search(r'\d{4}', message):  # Si contiene 4 d√≠gitos
            logger.info("üéØ Acci√≥n detectada: verify_patient")
            digits = re.findall(r'\d{4}', message)[0]
            return ActionIntent(
                action="verify_patient",
                params={"last_four_digits": digits},
                confidence=0.75
            )
        
        return None
    
    def _extract_appointment_data(self, message: str) -> dict:
        """
        Extrae fecha, hora y motivo del mensaje del usuario

        Ejemplo: 
        - "Quiero agendar para el lunes 25 a las 10:00"
        - "Agendar cita ma√±ana 14:40"
        - "Quiero cita el 2025-11-20 por la ma√±ana"

        Returns:
            dict con keys: fecha, hora, motivo
        """

        import re
        from datetime import datetime, timedelta

        extracted = {
            "fecha": None,
            "hora": None,
            "motivo": None
        }

        message_lower = message.lower()
        logger.info(f"üìä Extrayendo datos de mensaje: {message_lower}")

        # Extraer fecha: 2025-10-20T04:00:00.000Z
        fecha_iso = re.search(r'(\d{2}-\d{2}-\d{2})', message_lower)
        if fecha_iso:
            extracted["fecha"] = fecha_iso.group(0)
            logger.info(f"üìä Fecha extra√≠da (ISO): {extracted['fecha']}")
        
        # Patron: 2025-10-20T04:00:00.000Z
        fecha_slash = re.search(r'(\d{4}/\d{2}/\d{2})', message_lower)
        if fecha_slash and not extracted["fecha"]:
            fecha_str = fecha_slash.group(0)
            logger.info(f"üìä Fecha extra√≠da (Slash): {extracted['fecha']}")
            try:
                # convertir a formato ISO
                if '/' in fecha_str:
                    parts: fecha_str.split('/')
                else:
                    parts = fecha_str.split('-')
                dia = int(parts[0])
                mes = int(parts[1])
                anio = int(parts[2])

                if anio < 100:
                    anio += 2000  # Asumir siglo 2000

                fecha = datetime(anio, mes, dia)
                extracted["fecha"] = f"{anio}-{mes:02d}-{dia:02d}T00:00:00.000Z"
                logger.info(f"üìä Fecha extra√≠da (ISO): {extracted['fecha']}")
            except:
                pass

        # Palabras clave temporales
        if not extracted['fecha']:
            hoy = datetime.now()

            if any(word in message_lower for word in ['hoy', 'hoi']):
                extracted['fecha'] = hoy.strftime("%Y-%m-%dT00:00:00.000Z")
                logger.info(f"üìä Fecha extra√≠da (Hoy): {extracted['fecha']}")

            elif any(word in message_lower for word in ['ma√±ana', 'manana']):
                manana = hoy + timedelta(days=1)
                extracted['fecha'] = manana.strftime("%Y-%m-%dT00:00:00.000Z")
                logger.info(f"üìä Fecha extra√≠da (Ma√±ana): {extracted['fecha']}")

            elif 'pasado ma√±ana' in message_lower:
                pasado_manana = hoy + timedelta(days=2)
                extracted['fecha'] = pasado_manana.strftime("%Y-%m-%dT00:00:00.000Z")
                logger.info(f"üìä Fecha extra√≠da (Pasado Ma√±ana): {extracted['fecha']}")

            dias_semana = {
                'lunes': 0, 'martes': 1, 'mi√©rcoles': 2, 'miercoles': 2,
                'jueves': 3, 'viernes': 4, 's√°bado': 5, 'sabado': 5, 'domingo': 6
            }

            for dia_nombre, dia_num in dias_semana.items():
                if dia_nombre in message_lower:
                    dias_a_sumar = (dia_num - hoy.weekday() + 7) % 7
                    if dias_a_sumar == 0:
                        dias_a_sumar = 7  # Pr√≥ximo semana
                    fecha_dia = hoy + timedelta(days=dias_a_sumar)
                    extracted['fecha'] = fecha_dia.strftime("%Y-%m-%dT00:00:00.000Z")
                    logger.info(f"üìä Fecha extra√≠da ({dia_nombre.capitalize()}): {extracted['fecha']}")
                    break
        # Extraer hora: formato 04:00:00.000Z o 14:30
        hora_match = re.search(r'(\d{1,2}:\d{2}(?::\d{2}(?:\.\d{3}Z)?)?)', message_lower)
        if hora_match:
            hora = int(hora_match.group(1).split(':')[0])
            minuto = int(hora_match.group(1).split(':')[1])
            periodo = 'AM' if hora < 12 else 'PM'
            logger.info(f"üìä Hora extra√≠da: {hora}:{minuto:02d} {periodo}")

            #Convertir a 24h si es am/pm
            if 'pm' in message_lower and hora < 12:
                hora += 12
            elif 'am' in message_lower and hora == 12:
                hora = 0

            extracted['hora'] = f"{hora:02d}:{minuto:02d}:00.000Z"
            logger.info(f"üìä Hora extra√≠da (24h): {extracted['hora']}")

        # Horarios textuales
        horarios_text = {
            'ma√±ana': '09:00:00.000Z',
            'tarde': '15:00:00.000Z',
            'noche': '19:00:00.000Z',
        }

        if not extracted["hora"]:
            for texto, hora in horarios_text.items():
                if texto in message_lower:
                    extracted['hora'] = hora
                    logger.info(f"üìä Hora extra√≠da (Texto): {extracted['hora']}")
                    break
        
        # Extraccion de motivo

        motivos_keywords = {
            'control': 'Control de rutina',
            'revision': 'Revision medica',
            'sintomas': 'Consulta por sintomas',
            'medicacion': 'Consulta de medicacion',
            'resultados': 'Consulta de resultados',
            'emergencia': 'Emergencia'
        }

        for keyword, motivo in motivos_keywords.items():
            if keyword in message_lower:
                extracted['motivo'] = motivo
                logger.info(f"üìä Motivo extra√≠do: {motivo}")
                break

        return extracted

    def extract_structured_data(self, text: str) -> Optional[dict]:
        """
        Extrae datos estructurados (JSON) de la respuesta del modelo.
        
        A veces el modelo genera respuestas con formato JSON para
        integraciones. Esta funci√≥n los extrae.
        
        Args:
            text: Texto que puede contener JSON
        
        Returns:
            Dict con los datos si se encuentran, None si no
        """
        try:
            # Buscar JSON en el texto
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(json_pattern, text)
            
            if matches:
                # Intentar parsear el primer match
                data = json.loads(matches[0])
                logger.info(f"üìä Datos estructurados extra√≠dos: {data}")
                return data
        except Exception as e:
            logger.debug(f"No se pudo extraer JSON: {e}")
        
        return None
    
    # ===== M√©todos Privados =====
    
    async def _build_prompt(
        self,
        conversation: Conversation,
        user_id: str
    ) -> str:
        """
        Construye el prompt con FORMATO ESTRUCTURADO.
        
        NUEVO FORMATO alineado con el modelo fine-tuned estructurado:
        <SYS>
        ... instrucciones del sistema ...
        </SYS>
        
        <DATA>
        Paciente_registrado = True/False
        Nombre = "Nombre Real" o None
        Citas = [...] o []
        Ultima_visita = "fecha" o None
        </DATA>
        
        <USER>: mensaje
        <ASSISTANT>:
        
        Args:
            conversation: Conversaci√≥n con historial
            user_id: ID del usuario (tel√©fono) para consultar BD
        
        Returns:
            Prompt estructurado completo
        """
        # 1. BLOQUE <SYS> - Instrucciones del sistema
        system_block = f"""<SYS>
Eres un asistente virtual especializado SOLO en Tuberculosis del centro de salud {settings.medical_center_name}.
Responde solo con informaci√≥n basada en los datos proporcionados en <DATA>.
SI NO hay datos expl√≠citos, debes responder: "No tengo esa informaci√≥n registrada".
NUNCA inventes nombres, fechas o informaci√≥n que no est√© en <DATA>.
M√°ximo 2 oraciones por respuesta.
Si preguntan algo fuera de Tuberculosis, responde: "Lo siento, solo atiendo consultas sobre Tuberculosis".
</SYS>"""
        
        # 2. BLOQUE <DATA> - Consultar paciente en BD
        patient_data = None
        patient_registered = False
        
        if self.patient_service:
            try:
                patient_registered, patient_data = await self.patient_service.verify_patient(
                    phone_number=user_id
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error consultando BD: {e}")
        
        # Construir bloque <DATA> estructurado
        data_lines = []
        data_lines.append(f"Paciente_registrado = {patient_registered}")
        
        if patient_registered and patient_data:
            nombre = patient_data.get('nombre', 'N/A')
            data_lines.append(f'Nombre = "{nombre}"')
            
            # Obtener pr√≥xima cita
            proxima_cita = patient_data.get('proxima_cita')
            if proxima_cita and isinstance(proxima_cita, dict):
                logger.info(f"üìä Pr√≥xima cita encontrada: {proxima_cita}")
                fecha_programada = proxima_cita.get('fecha_programada', 'N/A')
                fecha = fecha_programada.split('T')[0] if 'T' in fecha_programada else fecha_programada
                hora = fecha_programada.split('T')[1].split('.')[0] if 'T' in fecha_programada else 'N/A'
                estado = proxima_cita.get('estado')
                estado_desc = estado.get('descripcion', 'N/A') if estado else 'N/A'
                logger.info(f"üìä Pr√≥xima cita - Fecha: {fecha}, Hora: {hora}, Estado: {estado_desc}")
                data_lines.append(f'Citas = [{{fecha: "{fecha}", hora: "{hora}", estado: "{estado_desc}"}}]')
            else:
                data_lines.append("Citas = []")
                logger.info("üìä Sin pr√≥ximas citas encontradas")
            
            # √öltima visita (si est√° disponible)
            ultima_visita = patient_data.get('ultima_visita')
            if ultima_visita:
                logger.info(f"üìä √öltima visita: {ultima_visita}")
                data_lines.append(f'Ultima_visita = "{ultima_visita}"')
            else:
                logger.info("üìä Sin √∫ltima visita registrada")
                data_lines.append("Ultima_visita = None")
        else:
            # Paciente NO registrado
            data_lines.append("Nombre = None")
            data_lines.append("Citas = []")
            data_lines.append("Ultima_visita = None")
            logger.info("üìä Paciente no registrado, datos por defecto en <DATA>")
        
        data_block = "\n".join(data_lines)
        logger.info(f"üìä Bloque <DATA> construido:\n{data_block}")
        
        # 3. HISTORIAL - Solo √∫ltimo mensaje del usuario (el actual)
        recent_messages = conversation.get_recent_messages(limit=10)
        logger.info(f"üìä Mensajes recientes obtenidos: {len(recent_messages)}")

        # Filtrar mensajes v√°lidos (sin corrupci√≥n)
        valid_messages = []
        for msg in recent_messages:
            # Saltar mensajes corruptos
            if any(word in msg.content.lower() for word in ['tuberaci√≥n', 'tuberculos', 'diego', '14003']):
                logger.warning(f"‚ö†Ô∏è Mensaje corrupto saltado: {msg.content[:50]}")
                continue
            
            # Saltar mensajes muy largos
            if len(msg.content) > 200:
                logger.warning(f"‚ö†Ô∏è Mensaje muy largo saltado")
                continue
            
            valid_messages.append(msg)

        # Construir historial
        history_lines = []

        if len(valid_messages) > 1:
            # Tomar todos EXCEPTO el ultimo
            for msg in valid_messages[:-1]:
                if msg.role == MessageRole.USER:
                    history_lines.append(f"<USER>: {msg.content}")
                elif msg.role == MessageRole.ASSISTANT:
                    history_lines.append(f"<ASSISTANT>: {msg.content}")
        history_block = "\n".join(history_lines) if history_lines else ""
        
        last_user_message = ""
        if valid_messages:
            last_msg = valid_messages[-1]
            if last_msg.role == MessageRole.USER:
                last_user_message = last_msg.content
            else:
                for msg in reversed(valid_messages):
                    if msg.role == MessageRole.USER:
                        last_user_message = msg.content
                        break
        
        if not last_user_message:
            last_user_message = "Hola"

        # 4. Construir prompt completo
        if history_block:
            prompt = f"""{system_block}

<DATA>
{data_block}
</DATA>

<HISTORY>
{history_block}
</HISTORY>

<USER>: {last_user_message}
<ASSISTANT>:"""
            
        else:
            prompt = f"""{system_block}

<DATA>
{data_block}
</DATA>

<USER>: {last_user_message}
<ASSISTANT>:"""
        
        logger.info(f"ÔøΩ Prompt estructurado construido (longitud: {len(prompt)} chars)")
        logger.info(f"Historial incluido: {'Si' if history_block else 'No'} ({len(history_lines)} mensajes)")
        logger.info(f"Prompt completo:\n{prompt}")
        
        return prompt
    
    def _generate_with_model(
        self,
        prompt: str,
        max_tokens: int,
        temperature: float
    ) -> str:
        """
        Genera texto usando el modelo de lenguaje con formato estructurado.
        
        Args:
            prompt: Prompt completo con formato <SYS>, <DATA>, <USER>
            max_tokens: M√°ximo de tokens a generar
            temperature: Temperatura del modelo
        
        Returns:
            Texto generado
        """
        import torch
        
        # Tokenizar el prompt con attention_mask
        inputs = self.tokenizer(
            prompt,
            return_tensors="pt",
            max_length=512,
            truncation=True,
            padding=True,
            return_attention_mask=True  # ‚úÖ CR√çTICO: Evita warnings
        )

        # Mover a dispositivo
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        # Obtener la longitud del prompt para extraer solo lo nuevo
        prompt_length = inputs['input_ids'].shape[1]
        
        # Agregar tokens de detencion
        stop_tokens = [
            self.tokenizer.encode("\n\n", add_special_tokens=False)[0],
            self.tokenizer.encode("\n:", add_special_tokens=False)[0],
            self.tokenizer.encode("<USER>", add_special_tokens=False)[0],
            self.tokenizer.eos_token_id,
        ]
        
        # Generar con el modelo
        with torch.no_grad():
            outputs = self.model.generate(
                input_ids = inputs['input_ids'],
                attention_mask = inputs['attention_mask'],
                max_new_tokens=min(max_tokens, 80),
                temperature=temperature,
                do_sample=True,
                top_p=0.9,
                top_k=50,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=stop_tokens,
                repetition_penalty=1.2,  # Penaliza repeticiones
                no_repeat_ngram_size=3,  # Evita n-gramas repetidos
                early_stopping=True 
            )
        
        # Decodificar SOLO los tokens nuevos (no el prompt completo)
        generated_tokens = outputs[0][prompt_length:]
        response = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)

        logger.info(f"üìù Respuesta bruta del modelo: {response}")
        
        # Limpiar la respuesta
        response = self._clean_response(response)

        if not response or len(response.strip()) < 5:
            logger.info("‚ö†Ô∏è Respuesta vac√≠a o muy corta, usando respuesta por defecto")
            # Generar respuesta contextual basada en el √∫ltimo mensaje
            return "No tengo esta informaci√≥n registrada. ¬øEn qu√© m√°s puedo ayudarte?"
        
        return response
    
    def _clean_response(self, response: str) -> str:
        """
        Limpia la respuesta del modelo.
        
        MEJORAS:
        1. Trunca despu√©s de 2 oraciones
        2. Remueve conversaciones ficticias
        3. Valida que sea una respuesta √∫nica
        """
        if not response:
            return ""
        
        # 1. Remover prefijos incorrectos
        prefixes = ["<ASSISTANT>:", "Asistente:", "Assistant:", ":"]
        for prefix in prefixes:
            if response.startswith(prefix):
                response = response[len(prefix):].strip()
        
        # 2. ‚úÖ TRUNCAR en marcadores de conversaci√≥n ficticia
        stop_markers = [
            "\n\n",           # Doble salto de l√≠nea
            "\n:",            # Nuevo di√°logo
            "\n<USER>:",      # Nuevo usuario
            "\n<ASSISTANT>:", # Nuevo asistente
            "Paciente:",      # Di√°logo del paciente
            "Usuario:",       # Di√°logo del usuario
        ]
        
        for marker in stop_markers:
            if marker in response:
                response = response.split(marker)[0]
                logger.debug(f"üî™ Truncado en marcador: {marker}")
        
        # 3. ‚úÖ LIMITAR A 2 ORACIONES
        sentences = self._split_sentences(response)
        
        if len(sentences) > 2:
            logger.warning(f"‚ö†Ô∏è Respuesta ten√≠a {len(sentences)} oraciones, truncando a 2")
            response = ". ".join(sentences[:2]) + "."
        
        # 4. Limpiar espacios m√∫ltiples
        response = " ".join(response.split())
        
        # 5. Asegurar que termina con puntuaci√≥n
        if response and response[-1] not in '.!?':
            response += "."
        
        return response.strip()

    def _split_sentences(self, text: str) -> list[str]:
        """
        Divide texto en oraciones.

        Detecta fin de oracion por:
        - Punto seguido de espacio y mayuscula
        - Signos de interrogacion o exclamacion
        """ 

        import re
        # Patr√≥n: Punto/Interrogaci√≥n/Exclamaci√≥n + Espacio + May√∫scula
        pattern = r'(?<=[.!?])\s+(?=[A-Z√Å√â√ç√ì√ö√ë])'
        
        sentences = re.split(pattern, text)
        
        # Limpiar oraciones vac√≠as
        sentences = [s.strip() for s in sentences if s.strip()]
        
        return sentences
    
    def _get_fallback_response(self, last_message: str) -> str:
        """
        Genera una respuesta de respaldo cuando el modelo falla.
        
        Args:
            last_message: √öltimo mensaje del usuario
        
        Returns:
            Respuesta contextual
        """
        last_message_lower = last_message.lower()
        
        # Respuestas contextuales seg√∫n palabras clave
        if any(word in last_message_lower for word in ['agendar', 'cita', 'programar']):
            return (
                f"¬°Claro! Te ayudo a agendar una cita en {settings.medical_center_name}. "
                f"¬øPara qu√© especialidad necesitas la cita?"
            )
        
        if any(word in last_message_lower for word in ['cancelar', 'anular']):
            return (
                "Entiendo que necesitas cancelar una cita. "
                "Para verificar tu identidad, ¬øme puedes dar los √∫ltimos 4 d√≠gitos de tu n√∫mero de tel√©fono?"
            )
        
        if any(word in last_message_lower for word in ['reprogramar', 'cambiar']):
            return (
                "Te ayudo a reprogramar tu cita. "
                "Primero, ¬øme das los √∫ltimos 4 d√≠gitos de tu tel√©fono para verificarte?"
            )
        
        if any(word in last_message_lower for word in ['hola', 'buenos', 'buenas']):
            return (
                f"¬°Hola! Bienvenido al asistente virtual de {settings.medical_center_name}. "
                f"¬øEn qu√© puedo ayudarte hoy? Puedo ayudarte a:\n"
                f"‚Ä¢ Agendar una cita\n"
                f"‚Ä¢ Consultar tus pr√≥ximas citas\n"
                f"‚Ä¢ Cancelar o reprogramar una cita"
            )
        
        # Respuesta gen√©rica
        return (
            f"Entiendo. ¬øPodr√≠as darme m√°s detalles? "
            f"Puedo ayudarte con citas m√©dicas en {settings.medical_center_name}."
        )
    
    def _is_valid_context(self, message: str) -> bool:
        """
        Valida que el mensaje est√© dentro del contexto permitido.
        
        Args:
            message: Mensaje del usuario
        
        Returns:
            True si el mensaje es v√°lido
        """
        # Palabras clave del dominio
        keywords = [
            'cita', 'agendar', 'reprogramar', 'cancelar', 'recordatorio',
            'pr√≥xima', 'doctor', 'm√©dico', 'consulta', 'paciente',
            settings.medical_center_name.lower()
        ]
        
        message_lower = message.lower()
        
        # Si contiene alguna palabra clave, es v√°lido
        if any(keyword in message_lower for keyword in keywords):
            return True
        
        # Si es un saludo o mensaje corto, es v√°lido
        greetings = ['hola', 'buenos', 'buenas', 'saludos', 'hi', 'hello']
        if any(greeting in message_lower for greeting in greetings):
            return True
        
        # Si es muy corto (< 50 caracteres), permitir (puede ser respuesta)
        if len(message) < 50:
            return True
        
        return False
    
    def _get_out_of_context_response(self) -> str:
        """
        Retorna mensaje para contexto inv√°lido.
        
        Returns:
            Mensaje de redirecci√≥n
        """
        return (
            f"Lo siento, solo puedo asistir con citas, recordatorios o "
            f"informaci√≥n del {settings.medical_center_name}. "
            f"¬øEn qu√© puedo ayudarte con tu cita?"
        )
