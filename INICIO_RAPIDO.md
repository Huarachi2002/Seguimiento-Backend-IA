# üöÄ Inicio R√°pido - WhatsApp AI Assistant con GPU

## ‚ö° Comienza aqu√≠

Si eres nuevo en el proyecto y quieres ponerlo en marcha r√°pidamente:

### 1Ô∏è‚É£ Clonar y entrar al proyecto

```powershell
cd c:\Users\PC\Desktop\UAGRM\SW2-2025\Grupal\whatsapp-ai-assistant\fastapi-backend
```

### 2Ô∏è‚É£ Crear y activar entorno virtual

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

### 3Ô∏è‚É£ Verificar GPU (opcional pero recomendado)

```powershell
python verificar_gpu.py
```

Esto te dir√°:
- ‚úÖ Si tienes GPU NVIDIA
- ‚úÖ Qu√© versi√≥n de CUDA tienes
- ‚úÖ Qu√© comando usar para instalar PyTorch

### 4Ô∏è‚É£ Instalar dependencias con GPU

**Opci√≥n A: Autom√°tico (Recomendado)**
```powershell
.\instalar_con_gpu.ps1
```

**Opci√≥n B: Manual**
```powershell
# Para CUDA 12.x
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Para CUDA 11.x
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Sin GPU (CPU)
pip install torch torchvision torchaudio

# Instalar resto de dependencias
pip install -r requirements.txt
```

### 5Ô∏è‚É£ Probar modelos

```powershell
python probar_modelo.py
```

Esto te permitir√°:
- Probar diferentes modelos antes de elegir
- Ver cu√°nta VRAM usa cada modelo
- Verificar que la GPU funciona correctamente

### 6Ô∏è‚É£ Configurar variables de entorno

```powershell
# Copiar el archivo de ejemplo
Copy-Item .env.example .env

# Editar .env con tu editor favorito
notepad .env
```

**Configuraci√≥n m√≠nima necesaria:**
```env
# Modelo (usa el que probaste en el paso 5)
MODEL_NAME=microsoft/DialoGPT-medium
DEVICE=cuda

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
CONVERSATION_TTL=3600
```

### 7Ô∏è‚É£ Iniciar Redis

```powershell
docker-compose up -d redis
```

### 8Ô∏è‚É£ Iniciar la aplicaci√≥n

```powershell
python -m uvicorn app.main:app --reload
```

**Deber√≠as ver:**
```
INFO:     Started server process
INFO:app.infrastructure.ai.model_loader:ü§ñ Cargando modelo...
INFO:app.infrastructure.ai.model_loader:‚úÖ Modelo cargado en cuda
INFO:app.infrastructure.redis.redis_client:‚úÖ Conectado a Redis
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000
```

### 9Ô∏è‚É£ Probar el API

**En otra terminal:**
```powershell
curl -X POST "http://localhost:8000/api/chat" `
  -H "Content-Type: application/json" `
  -d '{\"user_id\": \"test\", \"message\": \"Hola\"}'
```

**Respuesta esperada:**
```json
{
  "response": "¬°Hola! ¬øEn qu√© puedo ayudarte hoy?",
  "user_id": "test",
  "timestamp": "2024-01-15T10:30:00"
}
```

---

## üìö Documentaci√≥n Completa

### Para principiantes
- **[TUTORIAL_GPU_COMPLETO.md](TUTORIAL_GPU_COMPLETO.md)** - Tutorial paso a paso con explicaciones detalladas

### Para configuraci√≥n
- **[MODELOS_RECOMENDADOS.md](MODELOS_RECOMENDADOS.md)** - Comparativa de modelos y recomendaciones
- **[GUIA_REDIS_COMPLETA.md](GUIA_REDIS_COMPLETA.md)** - Todo sobre Redis en el proyecto

### Para arquitectura
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Arquitectura del sistema
- **[RESUMEN_PROYECTO.md](RESUMEN_PROYECTO.md)** - Resumen ejecutivo

---

## üÜò Soluci√≥n R√°pida de Problemas

| Problema | Soluci√≥n R√°pida |
|----------|-----------------|
| GPU no detectada | `nvidia-smi` ‚Üí Instalar drivers NVIDIA |
| CUDA out of memory | Cambiar a modelo m√°s peque√±o en `.env` |
| Redis connection refused | `docker-compose up -d redis` |
| Import errors | `.\instalar_con_gpu.ps1` |
| Modelo muy lento | Cambiar `DEVICE=cpu` a `DEVICE=cuda` en `.env` |

---

## üìä Requisitos del Sistema

### M√≠nimo (CPU)
- Python 3.9+
- 8GB RAM
- 5GB espacio en disco
- Redis

### Recomendado (GPU)
- Python 3.9-3.12 (evitar 3.13)
- 16GB RAM
- GPU NVIDIA con 4GB+ VRAM
- CUDA 11.8 o 12.x
- 10GB espacio en disco
- Redis

---

## üéØ Pr√≥ximos Pasos

1. ‚úÖ **B√°sico funcionando** ‚Üí Lee [TUTORIAL_GPU_COMPLETO.md](TUTORIAL_GPU_COMPLETO.md)
2. ‚úÖ **Optimizar modelo** ‚Üí Lee [MODELOS_RECOMENDADOS.md](MODELOS_RECOMENDADOS.md)
3. ‚úÖ **Integrar WhatsApp** ‚Üí Configura N8N o WhatsApp Business API
4. ‚úÖ **Producci√≥n** ‚Üí Configura PostgreSQL y deploy

---

## üîó Enlaces √ötiles

- **Hugging Face**: https://huggingface.co/models
- **PyTorch + CUDA**: https://pytorch.org/get-started/locally/
- **FastAPI**: https://fastapi.tiangolo.com/
- **Redis**: https://redis.io/docs/

---

## üí° Consejos

1. **Primera vez cargando modelo**: Tarda 5-10 minutos (se descarga)
2. **Siguientes veces**: Instant√°neo (ya est√° cacheado)
3. **Monitorear GPU**: Usa `nvidia-smi -l 1` en otra terminal
4. **Cambiar modelo**: Solo edita `.env` y reinicia

---

¬øProblemas? Revisa [TUTORIAL_GPU_COMPLETO.md](TUTORIAL_GPU_COMPLETO.md) ‚Üí Secci√≥n "Soluci√≥n de Problemas"
