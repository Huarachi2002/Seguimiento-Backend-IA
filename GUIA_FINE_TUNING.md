# ğŸ“ GuÃ­a Completa de Fine-Tuning para DialoGPT

## ğŸ“š Ãndice
1. [Â¿QuÃ© es Fine-Tuning?](#quÃ©-es-fine-tuning)
2. [PreparaciÃ³n](#preparaciÃ³n)
3. [Proceso de Entrenamiento](#proceso-de-entrenamiento)
4. [ComparaciÃ³n y Pruebas](#comparaciÃ³n-y-pruebas)
5. [IntegraciÃ³n en la AplicaciÃ³n](#integraciÃ³n-en-la-aplicaciÃ³n)
6. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ğŸ¯ Â¿QuÃ© es Fine-Tuning?

### Concepto Simple
Fine-Tuning es como darle un **curso especializado** a un estudiante que ya sabe hablar espaÃ±ol. El modelo DialoGPT ya sabe conversar, pero con Fine-Tuning aprende especÃ­ficamente sobre:

- âœ… Tu centro mÃ©dico (CAÃ‘ADA DEL CARMEN)
- âœ… CÃ³mo agendar citas
- âœ… El proceso de verificaciÃ³n de identidad
- âœ… Respuestas apropiadas a emergencias
- âœ… El tono y estilo profesional que necesitas

### CÃ³mo Funciona

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODELO BASE (DialoGPT-medium)                      â”‚
â”‚  - Sabe conversar en espaÃ±ol                        â”‚
â”‚  - Conocimiento general                             â”‚
â”‚  - 354 millones de parÃ¡metros                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
                    â”‚ + Tu Dataset
                    â”‚   (200 conversaciones mÃ©dicas)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FINE-TUNING (Entrenamiento)                        â”‚
â”‚  - Ajusta los pesos del modelo                      â”‚
â”‚  - Aprende patrones especÃ­ficos                     â”‚
â”‚  - DuraciÃ³n: 2-4 horas                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODELO PERSONALIZADO (DialoGPT-Medical)            â”‚
â”‚  - Especializado en conversaciones mÃ©dicas          â”‚
â”‚  - Conoce tu flujo de citas                         â”‚
â”‚  - Tono consistente y profesional                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### QuÃ© Cambia en el Modelo

| Aspecto | Antes (Base) | DespuÃ©s (Fine-Tuned) |
|---------|--------------|----------------------|
| **Respuestas** | GenÃ©ricas | EspecÃ­ficas de tu centro |
| **Tono** | Variable | Consistente y profesional |
| **Conocimiento** | General | Especializado en citas mÃ©dicas |
| **Flujo** | Desconocido | Conoce proceso de verificaciÃ³n |
| **Emergencias** | Puede confundirse | Responde correctamente |

---

## ğŸ› ï¸ PreparaciÃ³n

### PASO 1: Verificar Requisitos

```powershell
# Verificar que todo estÃ© listo
python verificar_sistema.py
```

**Debes tener:**
- âœ… GPU NVIDIA (RTX 4060 Ti âœ“)
- âœ… CUDA instalado (12.6 âœ“)
- âœ… PyTorch con CUDA (âœ“)
- âœ… Dataset preparado (medical_conversations.json âœ“)
- âœ… Espacio en disco: ~5GB libres

### PASO 2: Entender el Dataset

Tu archivo `medical_conversations.json` tiene **200 conversaciones** en formato:

```json
[
  {
    "user": "Hola, necesito una cita",
    "assistant": "Â¡Claro! Con gusto te ayudo..."
  }
]
```

**Calidad del Dataset:**
- âœ… **200 ejemplos** - Suficiente para fine-tuning bÃ¡sico
- âœ… **Variedad** - Saludos, citas, cancelaciones, emergencias
- âœ… **Tono consistente** - Profesional y amable
- âš ï¸ **Ideal:** 500-1000 ejemplos (puedes agregar mÃ¡s despuÃ©s)

---

## ğŸš€ Proceso de Entrenamiento

### PASO 1: Ejecutar el Entrenamiento

Abre PowerShell en tu proyecto y ejecuta:

```powershell
# Activar entorno virtual
.\venv\Scripts\Activate.ps1

```

### Â¿QuÃ© significan los parÃ¡metros?

| ParÃ¡metro | QuÃ© hace | Tu valor | Por quÃ© |
|-----------|----------|----------|---------|
| `--epochs` | CuÃ¡ntas veces recorre todo el dataset | `3` | Balance entre aprendizaje y overfitting |
| `--batch_size` | CuÃ¡ntos ejemplos procesa a la vez | `4` | Ajustado a tu VRAM de 8GB |
| `--learning_rate` | QuÃ© tan rÃ¡pido aprende | `5e-5` | EstÃ¡ndar para fine-tuning |

### PASO 2: Monitorear el Proceso

El entrenamiento mostrarÃ¡:

```
ğŸ–¥ï¸  Dispositivo: cuda
ğŸ® GPU: NVIDIA GeForce RTX 4060 Ti
ğŸ’¾ VRAM: 8.59 GB

ğŸ“‚ Cargando dataset desde: app/training/datasets/medical_conversations.json
âœ… Cargadas 200 conversaciones
âœ… Dataset procesado: 200 ejemplos
ğŸ“Š Train: 180 | Eval: 20

ğŸ¤– Cargando modelo base: microsoft/DialoGPT-medium
âœ… Tokenizer cargado
âœ… Modelo cargado en cuda
ğŸ“Š ParÃ¡metros: 354,823,168

ğŸ”¤ Tokenizando dataset...
âœ… Dataset tokenizado

======================================================================
ğŸš€ INICIANDO FINE-TUNING
======================================================================
ğŸ“Š ConfiguraciÃ³n:
   - Ã‰pocas: 3
   - Batch Size: 4
   - Learning Rate: 5e-05
   - Ejemplos de entrenamiento: 180
   - Ejemplos de evaluaciÃ³n: 20
======================================================================

ğŸ‹ï¸  Iniciando entrenamiento...
â° Esto tomarÃ¡ aproximadamente 2-4 horas
ğŸ’¡ Puedes monitorear la GPU con: nvidia-smi -l 1
```

### PASO 3: Durante el Entrenamiento

En **otra terminal PowerShell**, monitorea la GPU:

```powershell
nvidia-smi -l 1
```

VerÃ¡s algo como:

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |
|----------------------------------------------------------------------+----------------------+
| GPU  Name                  | Temperature | Power | Memory-Usage    | GPU-Util             |
|==========================================================================================|
|   0  NVIDIA GeForce RTX 4060 Ti |  65Â°C      | 120W  | 6500MiB/8188MiB | 95%              |
+-----------------------------------------------------------------------------------------+
```

**Indicadores saludables:**
- âœ… GPU-Util: 90-100% (estÃ¡ trabajando)
- âœ… Temperatura: 60-80Â°C (normal)
- âœ… Memory: 6-7GB usados (correcto)
- âš ï¸ Si Temp > 85Â°C: Mejorar ventilaciÃ³n

### PASO 4: Logs del Entrenamiento

Cada 50 pasos verÃ¡s:

```
{'loss': 2.543, 'learning_rate': 5e-05, 'epoch': 0.5}
{'loss': 2.234, 'learning_rate': 4.5e-05, 'epoch': 1.0}
{'loss': 1.987, 'learning_rate': 4e-05, 'epoch': 1.5}
{'loss': 1.756, 'learning_rate': 3.5e-05, 'epoch': 2.0}
```

**Â¿QuÃ© significa?**
- **loss** (pÃ©rdida): QuÃ© tan "perdido" estÃ¡ el modelo
  - âœ… Debe **bajar** con el tiempo
  - âœ… De ~3.0 a ~1.5-2.0 es excelente
  - âš ï¸ Si sube, hay problema

- **epoch**: CuÃ¡ntas veces ha visto todo el dataset
  - Va de 0.0 a 3.0

### PASO 5: FinalizaciÃ³n

Al terminar verÃ¡s:

```
======================================================================
âœ… ENTRENAMIENTO COMPLETADO
======================================================================
ğŸ“Š MÃ©tricas finales:
   - Loss de entrenamiento: 1.756
   - Tiempo total: 7234.56 segundos (2.01 horas)
======================================================================

ğŸ” Evaluando modelo...
======================================================================
ğŸ“Š RESULTADOS DE EVALUACIÃ“N
======================================================================
   - Loss de evaluaciÃ³n: 1.834
   - Perplexity: 6.26
======================================================================

ğŸ’¾ Guardando modelo entrenado en: app/training/models/dialogpt-medical
âœ… Modelo guardado exitosamente

======================================================================
ğŸ§ª PROBANDO GENERACIÃ“N DE RESPUESTAS
======================================================================

ğŸ‘¤ Usuario: Hola, necesito una cita
ğŸ¤– Asistente: Â¡Claro! Con gusto te ayudo a agendar una cita. Â¿Para quÃ© especialidad la necesitas?

ğŸ‘¤ Usuario: Quiero cancelar mi cita
ğŸ¤– Asistente: Entiendo que necesitas cancelar tu cita. Â¿PodrÃ­as decirme cuÃ¡l es el motivo de la cancelaciÃ³n?

======================================================================
ğŸ‰ Â¡PROCESO COMPLETO!
======================================================================
ğŸ“ Modelo guardado en: app/training/models/dialogpt-medical
ğŸ’¡ Para usarlo, actualiza tu .env:
   MODEL_NAME=app/training/models/dialogpt-medical
======================================================================
```

---

## ğŸ” ComparaciÃ³n y Pruebas

### PASO 1: Comparar Modelos

Ejecuta el comparador:

```powershell
python app/training/train_gpt2_spanish.py
```

### PASO 2: Ver las Diferencias

El script mostrarÃ¡ comparaciones como:

```
================================================================================
Prueba 1/8
================================================================================

ğŸ‘¤ USUARIO: Hola, necesito una cita

ğŸ¤– MODELO BASE:
   Hola. Â¿En quÃ© puedo ayudarte?

âœ¨ MODELO FINE-TUNED:
   Â¡Claro! Con gusto te ayudo a agendar una cita en CAÃ‘ADA DEL CARMEN. 
   Â¿Para quÃ© especialidad la necesitas?

ğŸ“Š El modelo fine-tuned generÃ³ una respuesta mÃ¡s completa y especÃ­fica
```

### PASO 3: AnÃ¡lisis de Mejoras

**Aspectos a observar:**

| Criterio | Modelo Base | Modelo Fine-Tuned |
|----------|-------------|-------------------|
| **Especificidad** | GenÃ©rico | Menciona el centro mÃ©dico |
| **Flujo** | Sin estructura | Sigue proceso de agendamiento |
| **Tono** | Informal | Profesional y cÃ¡lido |
| **Contexto** | Limitado | Entiende contexto mÃ©dico |

---

## ğŸ”„ IntegraciÃ³n en la AplicaciÃ³n

### PASO 1: Actualizar `.env`

Cambia esta lÃ­nea en tu archivo `.env`:

```env
# ANTES (modelo base)
# MODEL_NAME=DeepESP/gpt2-spanish

# DESPUÃ‰S (modelo fine-tuned)
MODEL_NAME=app/training/models/gpt2-spanish-medical
```

### PASO 2: Reiniciar la AplicaciÃ³n

```powershell
# Detener el servidor (Ctrl+C)

# Reiniciar
python -m uvicorn app.main:app --reload
```

### PASO 3: Verificar que Carga el Modelo Correcto

En los logs verÃ¡s:

```
ğŸ”„ Iniciando carga del modelo: app/training/models/dialogpt-medical
ğŸ–¥ï¸ Dispositivo detectado: cuda
âœ… Modelo cargado exitosamente
```

### PASO 4: Probar en Postman

```http
POST http://localhost:8000/chat/
Content-Type: application/json

{
  "user_id": "+59170123456",
  "message": "Hola, necesito una cita"
}
```

**Ahora deberÃ­as ver respuestas mucho mejores:**

```json
{
  "response": "Â¡Claro! Con gusto te ayudo a agendar una cita en CAÃ‘ADA DEL CARMEN. Â¿Para quÃ© especialidad la necesitas?",
  "user_id": "+59170123456",
  "conversation_id": "conv_+59170123456_xxx",
  "action": "schedule_appointment",
  "params": {
    "status": "collecting_info"
  }
}
```

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### Â¿CÃ³mo saber si funcionÃ³?

Compara estos aspectos:

#### 1. **Perplexity** (Perplejidad)
- **QuÃ© es:** QuÃ© tan "confundido" estÃ¡ el modelo
- **Antes:** ~15-20 (modelo base)
- **DespuÃ©s:** ~6-8 (fine-tuned)
- âœ… **Menor es mejor**

#### 2. **Calidad de Respuestas**
- âœ… Menciona el centro mÃ©dico por nombre
- âœ… Usa el flujo correcto de agendamiento
- âœ… Tono consistente
- âœ… Respuestas relevantes al contexto

#### 3. **Velocidad**
- DeberÃ­a mantener la misma velocidad (~0.1-0.2s por respuesta)

---

## âš ï¸ SoluciÃ³n de Problemas

### Error: "CUDA out of memory"

**Causa:** Batch size muy grande para tu GPU

**SoluciÃ³n:**
```powershell
python app/training/train_model.py --epochs 3 --batch_size 2
```

### Error: "Loss no baja" o "Loss aumenta"

**Causa:** Learning rate muy alto

**SoluciÃ³n:**
```powershell
python app/training/train_model.py --epochs 3 --batch_size 4 --learning_rate 1e-5
```

### Error: "Modelo genera respuestas vacÃ­as"

**Causa:** Overfitting (demasiadas Ã©pocas)

**SoluciÃ³n:**
```powershell
python app/training/train_model.py --epochs 2 --batch_size 4
```

### Error: "RuntimeError: CUDA error"

**SoluciÃ³n:**
```powershell
# Limpiar cachÃ© de CUDA
python -c "import torch; torch.cuda.empty_cache()"

# Reiniciar y probar de nuevo
python app/training/train_model.py --epochs 3 --batch_size 4
```

---

## ğŸ“ Conceptos TÃ©cnicos Explicados

### Â¿QuÃ© son las "Ã‰pocas"?

Una **Ã©poca** es una pasada completa por todo el dataset.

```
Ã‰poca 1: Modelo ve las 200 conversaciones por primera vez
Ã‰poca 2: Modelo ve las 200 conversaciones de nuevo (reforzando)
Ã‰poca 3: Modelo ve las 200 conversaciones por tercera vez (consolidando)
```

**Â¿Por quÃ© 3?**
- 1 Ã©poca: Aprendizaje insuficiente
- 3 Ã©pocas: Balance perfecto
- 5+ Ã©pocas: Overfitting (memoriza en vez de aprender)

### Â¿QuÃ© es el "Batch Size"?

El **batch size** es cuÃ¡ntos ejemplos procesa a la vez.

```
Batch Size 4:
- Toma 4 conversaciones
- Procesa juntas
- Actualiza el modelo
- Repite con las siguientes 4
```

**Tu GPU (8GB VRAM):**
- Batch Size 2: Seguro pero mÃ¡s lento
- **Batch Size 4: Ã“ptimo** â­
- Batch Size 8: Puede dar error de memoria

### Â¿QuÃ© es el "Learning Rate"?

El **learning rate** controla quÃ© tan grandes son los cambios en cada paso.

```
Learning Rate Alto (1e-3):
  - Aprende rÃ¡pido
  - Puede "pasarse" y no converger

Learning Rate Medio (5e-5): â­ RECOMENDADO
  - Aprende de forma estable
  - Balance perfecto

Learning Rate Bajo (1e-6):
  - Aprende muy lento
  - Necesita muchas Ã©pocas
```

---

## ğŸ“ˆ Mejoras Futuras

### 1. **Agregar mÃ¡s datos**

Si tienes conversaciones reales del centro:

```json
// Agregar al medical_conversations.json
{
  "user": "ConversaciÃ³n real de un paciente",
  "assistant": "Respuesta real que dio el personal"
}
```

Re-entrena con mÃ¡s datos cada 3-6 meses.

### 2. **Ajuste fino de hiperparÃ¡metros**

Experimenta con:

```powershell
# MÃ¡s conservador (menos overfitting)
python app/training/train_model.py --epochs 2 --batch_size 4 --learning_rate 2e-5

# MÃ¡s agresivo (aprendizaje mÃ¡s fuerte)
python app/training/train_model.py --epochs 4 --batch_size 4 --learning_rate 7e-5
```

### 3. **ValidaciÃ³n con usuarios reales**

DespuÃ©s del fine-tuning, monitorea:
- Â¿Los usuarios estÃ¡n satisfechos?
- Â¿Las respuestas son apropiadas?
- Â¿Hay casos que el modelo no maneja bien?

Agrega esos casos al dataset y re-entrena.

---

## âœ… Checklist Final

Antes de usar en producciÃ³n:

- [ ] Entrenamiento completado sin errores
- [ ] Loss final < 2.0
- [ ] Perplexity < 10
- [ ] ComparaciÃ³n muestra mejoras claras
- [ ] Pruebas en Postman exitosas
- [ ] Respuestas apropiadas al contexto
- [ ] Modelo guardado correctamente
- [ ] `.env` actualizado
- [ ] AplicaciÃ³n inicia sin errores
- [ ] Respuestas en tiempo real (< 0.5s)

---

## ğŸ‰ Â¡Ã‰xito!

Si completaste todos los pasos, ahora tienes:

âœ… Un modelo DialoGPT especializado en conversaciones mÃ©dicas  
âœ… Respuestas especÃ­ficas de tu centro mÃ©dico  
âœ… Tono profesional y consistente  
âœ… Mejor manejo del flujo de agendamiento  

**PrÃ³ximo paso:** Integrar con WhatsApp vÃ­a n8n ğŸš€
